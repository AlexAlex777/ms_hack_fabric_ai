{"cells":[{"cell_type":"code","source":["# Welcome to your new notebook\n","# Type here in the cell editor to add code!\n","import os\n","print(os.listdir(\"/lakehouse/default/Files/yaml/\"))"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"496f65ab-0725-4596-9893-497a0a2f14d2","statement_id":5,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-01T07:17:36.3019371Z","session_start_time":null,"execution_start_time":"2024-03-01T07:17:36.917344Z","execution_finish_time":"2024-03-01T07:17:37.7938417Z","parent_msg_id":"cd610e83-19a4-4510-8a07-0566237acdc7"},"text/plain":"StatementMeta(, 496f65ab-0725-4596-9893-497a0a2f14d2, 5, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["['data.yaml']\n"]}],"execution_count":3,"metadata":{},"id":"7e23d74a-58f3-4ba3-9f07-8745df948651"},{"cell_type":"code","source":["print(open(\"/lakehouse/default/Files/yaml/data.yaml\"))"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"496f65ab-0725-4596-9893-497a0a2f14d2","statement_id":6,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-01T07:17:36.4321039Z","session_start_time":null,"execution_start_time":"2024-03-01T07:17:38.2976137Z","execution_finish_time":"2024-03-01T07:17:39.1546862Z","parent_msg_id":"b4cbd3e0-19fd-4dec-9c6d-3dbf27ee772c"},"text/plain":"StatementMeta(, 496f65ab-0725-4596-9893-497a0a2f14d2, 6, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["<_io.TextIOWrapper name='/lakehouse/default/Files/yaml/data.yaml' mode='r' encoding='UTF-8'>\n"]}],"execution_count":4,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"aa5688ec-706e-4265-8c97-701d91d9e063"},{"cell_type":"code","source":["%pip install ultralytics"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":-1,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-01T07:17:36.645713Z","session_start_time":null,"execution_start_time":"2024-03-01T07:18:49.7499122Z","execution_finish_time":"2024-03-01T07:18:49.7500415Z","parent_msg_id":"0d90b958-6c53-4c9b-81fa-e16025612b1b"},"text/plain":"StatementMeta(, , -1, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n  Downloading ultralytics-8.1.20-py3-none-any.whl (716 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m716.3/716.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from ultralytics) (3.7.2)\nCollecting opencv-python>=4.6.0 (from ultralytics)\n  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: pillow>=7.1.2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from ultralytics) (10.0.1)\nRequirement already satisfied: pyyaml>=5.3.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from ultralytics) (6.0.1)\nRequirement already satisfied: requests>=2.23.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from ultralytics) (2.31.0)\nRequirement already satisfied: scipy>=1.4.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from ultralytics) (1.10.1)\nRequirement already satisfied: torch>=1.8.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from ultralytics) (2.0.1)\nCollecting torchvision>=0.9.0 (from ultralytics)\n  Downloading torchvision-0.17.1-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m169.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm>=4.64.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from ultralytics) (4.66.1)\nRequirement already satisfied: psutil in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from ultralytics) (5.9.5)\nCollecting py-cpuinfo (from ultralytics)\n  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\nCollecting thop>=0.1.1 (from ultralytics)\n  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\nRequirement already satisfied: pandas>=1.1.4 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from ultralytics) (2.0.3)\nRequirement already satisfied: seaborn>=0.11.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nRequirement already satisfied: contourpy>=1.0.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.1)\nRequirement already satisfied: cycler>=0.10 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.43.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\nRequirement already satisfied: numpy>=1.20 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.1)\nRequirement already satisfied: idna<4,>=2.5 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.17)\nRequirement already satisfied: certifi>=2017.4.17 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\nRequirement already satisfied: filelock in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.11.0)\nRequirement already satisfied: typing-extensions in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.5.0)\nRequirement already satisfied: sympy in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.12)\nRequirement already satisfied: networkx in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.2)\nRequirement already satisfied: jinja2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\nCollecting torch>=1.8.0 (from ultralytics)\n  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting typing-extensions>=4.8.0 (from torch>=1.8.0->ultralytics)\n  Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\nRequirement already satisfied: fsspec in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2023.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m115.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m178.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m149.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting triton==2.2.0 (from torch>=1.8.0->ultralytics)\n  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m131.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: six>=1.5 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nInstalling collected packages: py-cpuinfo, typing-extensions, triton, opencv-python, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, thop, ultralytics\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.5.0\n    Not uninstalling typing-extensions at /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages, outside environment /nfs4/pyenv-6649b43b-a25a-46eb-a35b-07768b3889c6\n    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n  Attempting uninstall: torch\n    Found existing installation: torch 2.0.1\n    Not uninstalling torch at /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages, outside environment /nfs4/pyenv-6649b43b-a25a-46eb-a35b-07768b3889c6\n    Can't uninstall 'torch'. No files were found to uninstall.\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nsentence-transformers 2.0.0 requires sentencepiece, which is not installed.\ndash 2.14.0 requires Flask<2.3.0,>=1.0.4, but you have flask 3.0.0 which is incompatible.\ndash 2.14.0 requires Werkzeug<2.3.0, but you have werkzeug 3.0.1 which is incompatible.\ntensorflow 2.12.1 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 opencv-python-4.9.0.80 py-cpuinfo-9.0.0 thop-0.1.1.post2209072238 torch-2.2.1 torchvision-0.17.1 triton-2.2.0 typing-extensions-4.10.0 ultralytics-8.1.20\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\nWarning: PySpark kernel has been restarted to use updated packages.\n\n"]}],"execution_count":5,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"8d760ddc-ec53-4ae5-ad89-e26302cea014"},{"cell_type":"code","source":["%pip install opencv-python-headless imutils"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":-1,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-01T07:17:36.9829831Z","session_start_time":null,"execution_start_time":"2024-03-01T07:19:08.5260686Z","execution_finish_time":"2024-03-01T07:19:08.526219Z","parent_msg_id":"51c5bf01-2d5a-4d0a-9475-ee7333b218bd"},"text/plain":"StatementMeta(, , -1, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting opencv-python-headless\n  Downloading opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting imutils\n  Downloading imutils-0.5.4.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\n\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from opencv-python-headless) (1.24.3)\nBuilding wheels for collected packages: imutils\n  Building wheel for imutils (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\n\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25837 sha256=71c0bb40367a2dee6ead49a3808e82a863917c180494c880c93e7ea787ab26f0\n  Stored in directory: /home/trusted-service-user/.cache/pip/wheels/85/cf/3a/e265e975a1e7c7e54eb3692d6aa4e2e7d6a3945d29da46f2d7\nSuccessfully built imutils\nInstalling collected packages: imutils, opencv-python-headless\nSuccessfully installed imutils-0.5.4 opencv-python-headless-4.9.0.80\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\nWarning: PySpark kernel has been restarted to use updated packages.\n\n"]}],"execution_count":6,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"11abf2b7-9b60-451e-b7ea-24cf7a8f8d76"},{"cell_type":"code","source":["%pip install wandb"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":-1,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-01T07:17:37.139662Z","session_start_time":null,"execution_start_time":"2024-03-01T07:19:28.1531886Z","execution_finish_time":"2024-03-01T07:19:28.1533371Z","parent_msg_id":"3394e10f-4b1a-4540-9e62-d10bb3e2289b"},"text/plain":"StatementMeta(, , -1, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: wandb in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (0.15.12)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from wandb) (3.1.40)\nRequirement already satisfied: requests<3,>=2.0.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from wandb) (5.9.5)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from wandb) (1.32.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: pathtools in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: setproctitle in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from wandb) (68.2.2)\nRequirement already satisfied: appdirs>=1.4.3 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from wandb) (4.21.12)\nRequirement already satisfied: six>=1.4.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.1)\nRequirement already satisfied: idna<4,>=2.5 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.17)\nRequirement already satisfied: certifi>=2017.4.17 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\nRequirement already satisfied: smmap<6,>=3.0.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\nWarning: PySpark kernel has been restarted to use updated packages.\n\n"]}],"execution_count":7,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"06d63e02-fe79-4d02-8102-8744513facad"},{"cell_type":"code","source":["import wandb\n","wandb.login(key=\"802e494553876d272ae0c83d17845a2832d2cd29\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"496f65ab-0725-4596-9893-497a0a2f14d2","statement_id":25,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-01T07:17:37.3203304Z","session_start_time":null,"execution_start_time":"2024-03-01T07:19:32.7856934Z","execution_finish_time":"2024-03-01T07:19:40.8110673Z","parent_msg_id":"b8c414bd-3788-4ae6-a696-bba4e4ef9fd5"},"text/plain":"StatementMeta(, 496f65ab-0725-4596-9893-497a0a2f14d2, 25, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/trusted-service-user/.netrc\n"]},{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"True"},"metadata":{}}],"execution_count":8,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"c0dfc771-a9cc-4cd4-bc25-8acb249ad313"},{"cell_type":"code","source":["from ultralytics import YOLO\n","model = YOLO(\"yolov8n\")\n","print(model)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"496f65ab-0725-4596-9893-497a0a2f14d2","statement_id":26,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-01T07:17:37.5535994Z","session_start_time":null,"execution_start_time":"2024-03-01T07:19:41.2007Z","execution_finish_time":"2024-03-01T07:19:51.0619162Z","parent_msg_id":"92068f13-1ca1-41f9-bd42-a61d3115f8d5"},"text/plain":"StatementMeta(, 496f65ab-0725-4596-9893-497a0a2f14d2, 26, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\nYOLO(\n  (model): DetectionModel(\n    (model): Sequential(\n      (0): Conv(\n        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (1): Conv(\n        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (2): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (3): Conv(\n        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (4): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0-1): 2 x Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (5): Conv(\n        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (6): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0-1): 2 x Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (7): Conv(\n        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (8): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (9): SPPF(\n        (cv1): Conv(\n          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n      )\n      (10): Upsample(scale_factor=2.0, mode='nearest')\n      (11): Concat()\n      (12): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (13): Upsample(scale_factor=2.0, mode='nearest')\n      (14): Concat()\n      (15): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (16): Conv(\n        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (17): Concat()\n      (18): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (19): Conv(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (20): Concat()\n      (21): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (22): Detect(\n        (cv2): ModuleList(\n          (0): Sequential(\n            (0): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (1): Sequential(\n            (0): Conv(\n              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (2): Sequential(\n            (0): Conv(\n              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n          )\n        )\n        (cv3): ModuleList(\n          (0): Sequential(\n            (0): Conv(\n              (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (1): Conv(\n              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (1): Sequential(\n            (0): Conv(\n              (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (1): Conv(\n              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (2): Sequential(\n            (0): Conv(\n              (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (1): Conv(\n              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n          )\n        )\n        (dfl): DFL(\n          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        )\n      )\n    )\n  )\n)\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6.23M/6.23M [00:00<00:00, 91.4MB/s]\n"]}],"execution_count":9,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"cd8f1f37-7a43-4676-8074-8b3d0d576435"},{"cell_type":"code","source":["yaml = \"/lakehouse/default/Files/yaml/data.yaml\""],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"496f65ab-0725-4596-9893-497a0a2f14d2","statement_id":27,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-01T07:17:37.8121767Z","session_start_time":null,"execution_start_time":"2024-03-01T07:19:51.3612103Z","execution_finish_time":"2024-03-01T07:19:51.5848478Z","parent_msg_id":"3646c5da-3a3a-4e8a-b00b-6e93ccfa49c1"},"text/plain":"StatementMeta(, 496f65ab-0725-4596-9893-497a0a2f14d2, 27, Finished, Available)"},"metadata":{}}],"execution_count":10,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"98b74a20-1bee-4ea6-9be0-af2d7d59ed8d"},{"cell_type":"code","source":["import mlflow"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"496f65ab-0725-4596-9893-497a0a2f14d2","statement_id":28,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-01T07:17:38.050594Z","session_start_time":null,"execution_start_time":"2024-03-01T07:19:51.9139152Z","execution_finish_time":"2024-03-01T07:19:52.1229775Z","parent_msg_id":"6a5081b2-f287-4d80-ba32-a6d8c277eb9a"},"text/plain":"StatementMeta(, 496f65ab-0725-4596-9893-497a0a2f14d2, 28, Finished, Available)"},"metadata":{}}],"execution_count":11,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"882ce713-ec56-4845-94f0-867919f965ac"},{"cell_type":"code","source":["try:\n","    mlflow.search_experiments()\n","    \n","except:\n","    print(\"No experiments yet\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"496f65ab-0725-4596-9893-497a0a2f14d2","statement_id":29,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-01T07:17:38.2193592Z","session_start_time":null,"execution_start_time":"2024-03-01T07:19:52.4178554Z","execution_finish_time":"2024-03-01T07:19:54.7836034Z","parent_msg_id":"a4f5fa75-2355-43d3-afb0-ed0bfa139591"},"text/plain":"StatementMeta(, 496f65ab-0725-4596-9893-497a0a2f14d2, 29, Finished, Available)"},"metadata":{}}],"execution_count":12,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"fa38bec3-02b1-4f82-a384-fc7e28cb181c"},{"cell_type":"code","source":["valid_experiment_name = \"Yolov8_Acne_Eczema_Finetuning2\"\n","mlflow.set_experiment(valid_experiment_name)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"496f65ab-0725-4596-9893-497a0a2f14d2","statement_id":31,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-01T07:17:38.7180751Z","session_start_time":null,"execution_start_time":"2024-03-01T07:19:55.7514478Z","execution_finish_time":"2024-03-01T07:19:56.5194007Z","parent_msg_id":"cc31f4a6-ec8c-47f5-b121-d69af868aed9"},"text/plain":"StatementMeta(, 496f65ab-0725-4596-9893-497a0a2f14d2, 31, Finished, Available)"},"metadata":{}},{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"<Experiment: artifact_location='', creation_time=1709216013414, experiment_id='9d3e91f4-3519-46d1-9088-16b30d693b46', last_update_time=None, lifecycle_stage='active', name='Yolov8_Acne_Eczema_Finetuning2', tags={}>"},"metadata":{}}],"execution_count":14,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"8ead9d92-4dbb-4cdd-bbce-05741a4d8780"},{"cell_type":"code","source":["model.train(data = yaml, \n","            epochs = 50, \n","            imgsz = 640, \n","            batch = 8,\n","            save_period = 5,\n","            project=\"yolov8FT\",  # Set your project directory\n","            name=\"run1\",  # Set a name for this particular training run\n","            exist_ok=True)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"496f65ab-0725-4596-9893-497a0a2f14d2","statement_id":32,"state":"submitted","livy_statement_state":"running","queued_time":"2024-03-01T07:17:38.9318924Z","session_start_time":null,"execution_start_time":"2024-03-01T07:19:56.8873392Z","execution_finish_time":null,"parent_msg_id":"d04f5bdc-cae8-4639-93c2-95f45eec26ff"},"text/plain":"StatementMeta(, 496f65ab-0725-4596-9893-497a0a2f14d2, 32, Submitted, Running)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.1.20 🚀 Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon Platinum 8370C 2.80GHz)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/lakehouse/default/Files/yaml/data.yaml, epochs=50, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=5, cache=False, device=None, workers=8, project=yolov8FT, name=run1, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=yolov8FT/run1\nDownloading https://ultralytics.com/assets/Arial.ttf to '/home/trusted-service-user/.config/Ultralytics/Arial.ttf'...\nOverriding model.yaml nc=80 with nc=10\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    753262  ultralytics.nn.modules.head.Detect           [10, [64, 128, 256]]          \nModel summary: 225 layers, 3012798 parameters, 3012782 gradients, 8.2 GFLOPs\n\nTransferred 319/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov8FT/run1', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\nWARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 135, len(boxes) = 4940. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\nWARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 62, len(boxes) = 595. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\nPlotting labels to yolov8FT/run1/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n\u001b[34m\u001b[1mMLflow: \u001b[0mlogging run_id(593c74d9-516c-486e-a2ff-7a59e9b05f5c) to sds://pbipneu6-northeurope.pbidedicated.windows.net/webapi/capacities/95e21aae-6a0b-49fb-94c1-e430b392fb52/workloads/ML/ML/Automatic/workspaceid/207baa19-22b5-4f4e-a3b0-9a7034fb125a/\n\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\nImage sizes 640 train, 640 val\nUsing 0 dataloader workers\nLogging results to \u001b[1myolov8FT/run1\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.468     0.0625     0.0552     0.0199\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595       0.65      0.109     0.0623     0.0221\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595        0.6      0.103      0.107      0.038\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.445      0.174     0.0979     0.0319\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.541      0.146      0.108     0.0425\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.322      0.208      0.127     0.0454\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.601      0.131      0.133     0.0451\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.361      0.187      0.167     0.0695\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.288      0.257      0.155     0.0553\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.342      0.243      0.165     0.0645\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.457      0.197      0.174     0.0615\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.291      0.276      0.206     0.0801\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.258      0.257      0.188      0.072\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.482      0.167      0.207     0.0785\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.251      0.278      0.195     0.0779\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.367      0.305      0.232     0.0956\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595       0.54      0.248      0.232     0.0927\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.557      0.245      0.256      0.108\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.432      0.266      0.245     0.0958\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.385      0.246      0.233     0.0919\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.476      0.224      0.222     0.0864\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.325      0.275      0.252      0.104\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.385      0.278      0.253      0.106\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.578      0.231      0.277      0.108\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.395      0.274      0.228     0.0915\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.426      0.302      0.249      0.105\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.439      0.298      0.264      0.112\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.418      0.277      0.232     0.0924\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.467      0.252      0.265      0.109\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.513      0.273      0.277      0.108\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.421      0.289      0.261      0.104\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.441      0.284      0.251      0.109\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.441      0.247      0.256      0.108\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.363      0.331      0.257      0.105\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.372      0.324      0.258      0.108\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.405      0.249      0.249      0.105\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.364        0.3      0.254      0.115\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.359      0.274      0.235     0.0939\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.372      0.276       0.26      0.106\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595       0.44       0.29      0.256      0.116\nClosing dataloader mosaic\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.393      0.306      0.259      0.112\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.354      0.334      0.267       0.11\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.381      0.342      0.275      0.119\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.379      0.343      0.277       0.12\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.363      0.312      0.274      0.117\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.383       0.34      0.266      0.115\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.363      0.311      0.262      0.117\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.386      0.344      0.269      0.119\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.384      0.347      0.281       0.12\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.374      0.337      0.278      0.123\n\n50 epochs completed in 6.419 hours.\nOptimizer stripped from yolov8FT/run1/weights/last.pt, 6.3MB\nOptimizer stripped from yolov8FT/run1/weights/best.pt, 6.3MB\n\nValidating yolov8FT/run1/weights/best.pt...\nUltralytics YOLOv8.1.20 🚀 Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon Platinum 8370C 2.80GHz)\nModel summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n                   all        266        595      0.375      0.338      0.278      0.123\n                  Acne        266         67      0.244      0.269      0.161     0.0468\n     Atopic Dermatitis        266         42      0.269      0.333      0.261     0.0747\n          Chicken Skin        266         98          1          0      0.142     0.0538\n                Eczema        266         51      0.353      0.471      0.347      0.155\nHansen-s Disease-Leprosy        266         36      0.172      0.194      0.162     0.0888\nHansen-s Disease-Leprosy- severe        266         21      0.298      0.143     0.0918     0.0339\n          Healthy skin        266         28     0.0918     0.0714     0.0256    0.00862\n             Psoriasis        266         87      0.368      0.448      0.328      0.142\n              Ringworm        266         30      0.486        0.8      0.749       0.38\n                 Warts        266        135      0.464      0.649      0.515      0.249\nSpeed: 0.8ms preprocess, 53.3ms inference, 0.0ms loss, 0.4ms postprocess per image\nResults saved to \u001b[1myolov8FT/run1\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 755k/755k [00:00<00:00, 17.3MB/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandru-baila\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.3 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.12\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/var/hadoop/tmp/nm-secondary-local-dir/usercache/trusted-service-user/appcache/application_1709276806049_0001/container_1709276806049_0001_01_000001/wandb/run-20240301_072042-y5sep23d\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrun1\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/alexandru-baila/yolov8FT\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/alexandru-baila/yolov8FT/runs/y5sep23d\u001b[0m\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /lakehouse/default/Files/train/labels.cache... 2103 images, 9 backgrounds, 0 corrupt: 100%|██████████| 2103/2103 [00:00<?, ?it/s]\n\u001b[34m\u001b[1mval: \u001b[0mScanning /lakehouse/default/Files/valid/labels.cache... 266 images, 2 backgrounds, 0 corrupt: 100%|██████████| 266/266 [00:00<?, ?it/s]\n2024/03/01 07:21:31 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n2024/03/01 07:21:31 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\n       1/50         0G      1.905       3.87      1.983         49        640: 100%|██████████| 263/263 [07:42<00:00,  1.76s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:26<00:00,  1.58s/it]\n       2/50         0G      1.773      3.257       1.89         19        640: 100%|██████████| 263/263 [07:37<00:00,  1.74s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:23<00:00,  1.38s/it]\n       3/50         0G      1.757      3.091      1.899         21        640: 100%|██████████| 263/263 [07:29<00:00,  1.71s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:21<00:00,  1.25s/it]\n       4/50         0G      1.759       2.96      1.872         16        640: 100%|██████████| 263/263 [07:15<00:00,  1.66s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:21<00:00,  1.26s/it]\n       5/50         0G      1.729      2.844      1.843         34        640: 100%|██████████| 263/263 [07:13<00:00,  1.65s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:22<00:00,  1.33s/it]\n       6/50         0G      1.715      2.766      1.827         29        640: 100%|██████████| 263/263 [07:18<00:00,  1.67s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:20<00:00,  1.22s/it]\n       7/50         0G      1.697      2.684      1.794         24        640: 100%|██████████| 263/263 [07:14<00:00,  1.65s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:22<00:00,  1.32s/it]\n       8/50         0G       1.66      2.583      1.798         29        640: 100%|██████████| 263/263 [07:14<00:00,  1.65s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:21<00:00,  1.26s/it]\n       9/50         0G      1.672      2.521      1.792         18        640: 100%|██████████| 263/263 [07:15<00:00,  1.66s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:23<00:00,  1.37s/it]\n      10/50         0G      1.663      2.462      1.764         36        640: 100%|██████████| 263/263 [07:00<00:00,  1.60s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:21<00:00,  1.27s/it]\n      11/50         0G      1.642      2.414      1.774         11        640: 100%|██████████| 263/263 [07:16<00:00,  1.66s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:21<00:00,  1.29s/it]\n      12/50         0G      1.638      2.347      1.744         23        640: 100%|██████████| 263/263 [07:35<00:00,  1.73s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:23<00:00,  1.37s/it]\n      13/50         0G      1.611      2.293      1.722         21        640: 100%|██████████| 263/263 [07:21<00:00,  1.68s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:23<00:00,  1.36s/it]\n      14/50         0G      1.609      2.287      1.739         27        640: 100%|██████████| 263/263 [07:19<00:00,  1.67s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:23<00:00,  1.37s/it]\n      15/50         0G      1.602      2.254      1.742         19        640: 100%|██████████| 263/263 [07:25<00:00,  1.70s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:22<00:00,  1.31s/it]\n      16/50         0G      1.617      2.215      1.731         22        640: 100%|██████████| 263/263 [07:24<00:00,  1.69s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:22<00:00,  1.34s/it]\n      17/50         0G      1.569      2.187      1.711         17        640: 100%|██████████| 263/263 [07:08<00:00,  1.63s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:22<00:00,  1.35s/it]\n      18/50         0G      1.598      2.172      1.714         44        640: 100%|██████████| 263/263 [07:21<00:00,  1.68s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:21<00:00,  1.29s/it]\n      19/50         0G      1.568      2.095      1.687         25        640: 100%|██████████| 263/263 [07:24<00:00,  1.69s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:21<00:00,  1.24s/it]\n      20/50         0G      1.566      2.071      1.688         29        640: 100%|██████████| 263/263 [07:07<00:00,  1.63s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:22<00:00,  1.30s/it]\n      21/50         0G       1.56      2.041      1.687         29        640: 100%|██████████| 263/263 [07:14<00:00,  1.65s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:21<00:00,  1.29s/it]\n      22/50         0G      1.542      2.003      1.673         17        640: 100%|██████████| 263/263 [07:07<00:00,  1.63s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:22<00:00,  1.34s/it]\n      23/50         0G      1.549       1.96       1.66         22        640: 100%|██████████| 263/263 [07:05<00:00,  1.62s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:22<00:00,  1.31s/it]\n      24/50         0G       1.53      1.916      1.646         33        640: 100%|██████████| 263/263 [07:17<00:00,  1.67s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:21<00:00,  1.29s/it]\n      25/50         0G      1.519        1.9      1.651         31        640: 100%|██████████| 263/263 [07:13<00:00,  1.65s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:21<00:00,  1.28s/it]\n      26/50         0G      1.527      1.879      1.648         26        640: 100%|██████████| 263/263 [07:14<00:00,  1.65s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:22<00:00,  1.31s/it]\n      27/50         0G        1.5      1.836      1.632         24        640: 100%|██████████| 263/263 [07:20<00:00,  1.67s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:20<00:00,  1.18s/it]\n      28/50         0G      1.486      1.816      1.625         34        640: 100%|██████████| 263/263 [07:08<00:00,  1.63s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:22<00:00,  1.31s/it]\n      29/50         0G      1.499      1.773       1.62         39        640: 100%|██████████| 263/263 [07:26<00:00,  1.70s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:19<00:00,  1.14s/it]\n      30/50         0G      1.483      1.751      1.617         17        640: 100%|██████████| 263/263 [07:09<00:00,  1.63s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:21<00:00,  1.24s/it]\n      31/50         0G      1.472      1.716      1.606         19        640: 100%|██████████| 263/263 [07:17<00:00,  1.66s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:21<00:00,  1.24s/it]\n      32/50         0G      1.469      1.713      1.609         16        640: 100%|██████████| 263/263 [07:04<00:00,  1.62s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:20<00:00,  1.21s/it]\n      33/50         0G      1.458      1.672      1.586         21        640: 100%|██████████| 263/263 [07:16<00:00,  1.66s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:21<00:00,  1.25s/it]\n      34/50         0G      1.449      1.636      1.591         21        640: 100%|██████████| 263/263 [07:09<00:00,  1.63s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:21<00:00,  1.25s/it]\n      35/50         0G      1.445      1.621       1.58         18        640: 100%|██████████| 263/263 [07:13<00:00,  1.65s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:22<00:00,  1.31s/it]\n      36/50         0G      1.436      1.646      1.589         27        640: 100%|██████████| 263/263 [07:08<00:00,  1.63s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:20<00:00,  1.22s/it]\n      37/50         0G      1.414      1.555      1.563         21        640: 100%|██████████| 263/263 [07:13<00:00,  1.65s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:22<00:00,  1.31s/it]\n      38/50         0G      1.414      1.552      1.561         17        640: 100%|██████████| 263/263 [07:00<00:00,  1.60s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:19<00:00,  1.18s/it]\n      39/50         0G      1.411      1.549      1.562         21        640: 100%|██████████| 263/263 [07:17<00:00,  1.66s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:21<00:00,  1.27s/it]\n      40/50         0G      1.387      1.491      1.538         18        640: 100%|██████████| 263/263 [07:14<00:00,  1.65s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:22<00:00,  1.34s/it]\n      41/50         0G      1.386      1.421      1.607         12        640: 100%|██████████| 263/263 [07:04<00:00,  1.61s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:21<00:00,  1.28s/it]\n      42/50         0G      1.362      1.362      1.604         15        640: 100%|██████████| 263/263 [07:04<00:00,  1.61s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:20<00:00,  1.23s/it]\n      43/50         0G      1.339       1.28      1.568         20        640: 100%|██████████| 263/263 [07:05<00:00,  1.62s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:20<00:00,  1.18s/it]\n      44/50         0G      1.326      1.294       1.57         16        640: 100%|██████████| 263/263 [07:11<00:00,  1.64s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:23<00:00,  1.38s/it]\n      45/50         0G      1.309      1.229      1.551         21        640: 100%|██████████| 263/263 [07:07<00:00,  1.63s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:21<00:00,  1.29s/it]\n      46/50         0G      1.299      1.203      1.536         13        640: 100%|██████████| 263/263 [07:13<00:00,  1.65s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:22<00:00,  1.31s/it]\n      47/50         0G      1.291      1.194      1.533         15        640: 100%|██████████| 263/263 [07:09<00:00,  1.63s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:21<00:00,  1.26s/it]\n      48/50         0G      1.283      1.177      1.522         22        640: 100%|██████████| 263/263 [07:15<00:00,  1.65s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:22<00:00,  1.31s/it]\n      49/50         0G      1.275      1.146      1.514         18        640: 100%|██████████| 263/263 [07:18<00:00,  1.67s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:20<00:00,  1.21s/it]\n      50/50         0G      1.265      1.138      1.519         14        640: 100%|██████████| 263/263 [07:16<00:00,  1.66s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:21<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 17/17 [00:15<00:00,  1.06it/s]\n"]},{"output_type":"display_data","data":{"application/vnd.mlflow.run-widget+json":{"info":{"artifact_uri":"sds://onelakenortheurope.pbidedicated.windows.net/207baa19-22b5-4f4e-a3b0-9a7034fb125a/027202b2-4275-419e-a3e9-55c9425cadfa/593c74d9-516c-486e-a2ff-7a59e9b05f5c/artifacts","end_time":1709300832,"experiment_id":"004d3fae-535b-498d-b0a7-4e0933d2da72","lifecycle_stage":"active","run_id":"593c74d9-516c-486e-a2ff-7a59e9b05f5c","run_name":"","run_uuid":"593c74d9-516c-486e-a2ff-7a59e9b05f5c","start_time":1709277691,"status":"FINISHED","user_id":"47b4be73-4385-4eda-a752-da9a9fee5a71"},"data":{"metrics":{"lr/pg0":0.00003541440000000003,"lr/pg2":0.00003541440000000003,"train/dfl_loss":1.5192,"train/box_loss":1.26507,"train/cls_loss":1.13752,"lr/pg1":0.00003541440000000003,"metrics/recallB":0.33782575511194174,"metrics/precisionB":0.37461526269254464,"val/cls_loss":2.98513,"val/box_loss":2.09737,"metrics/mAP50-95B":0.12329627584048744,"val/dfl_loss":2.29046,"metrics/mAP50B":0.2781552550678591},"params":{"task":"detect","mode":"train","model":"yolov8n.pt","data":"/lakehouse/default/Files/yaml/data.yaml","epochs":"50","time":"None","patience":"100","batch":"8","imgsz":"640","save":"True","save_period":"5","cache":"False","device":"None","workers":"0","project":"yolov8FT","name":"run1","exist_ok":"True","pretrained":"True","optimizer":"auto","verbose":"True","seed":"0","deterministic":"True","single_cls":"False","rect":"False","cos_lr":"False","close_mosaic":"10","resume":"False","amp":"True","fraction":"1.0","profile":"False","freeze":"None","multi_scale":"False","overlap_mask":"True","mask_ratio":"4","dropout":"0.0","val":"True","split":"val","save_json":"False","save_hybrid":"False","conf":"None","iou":"0.7","max_det":"300","half":"False","dnn":"False","plots":"True","source":"None","vid_stride":"1","stream_buffer":"False","visualize":"False","augment":"False","agnostic_nms":"False","classes":"None","retina_masks":"False","embed":"None","show":"False","save_frames":"False","save_txt":"False","save_conf":"False","save_crop":"False","show_labels":"True","show_conf":"True","show_boxes":"True","line_width":"None","format":"torchscript","keras":"False","optimize":"False","int8":"False","dynamic":"False","simplify":"False","opset":"None","workspace":"4","nms":"False","lr0":"0.01","lrf":"0.01","momentum":"0.937","weight_decay":"0.0005","warmup_epochs":"3.0","warmup_momentum":"0.8","warmup_bias_lr":"0.0","box":"7.5","cls":"0.5","dfl":"1.5","pose":"12.0","kobj":"1.0","label_smoothing":"0.0","nbs":"64","hsv_h":"0.015","hsv_s":"0.7","hsv_v":"0.4","degrees":"0.0","translate":"0.1","scale":"0.5","shear":"0.0","perspective":"0.0","flipud":"0.0","fliplr":"0.5","mosaic":"1.0","mixup":"0.0","copy_paste":"0.0","auto_augment":"randaugment","erasing":"0.4","crop_fraction":"1.0","cfg":"None","tracker":"botsort.yaml","save_dir":"yolov8FT/run1"},"tags":{"mlflow.user":"9b1bccca-b0b3-4fcf-9df5-fdeabefe9450","synapseml.notebook.artifactId":"281691d8-4c51-46c8-a259-c948faca46f2","synapseml.user.name":"Alexandru Baila","synapseml.user.id":"547b9905-28dd-451c-adad-86d787d2109b","synapseml.livy.id":"496f65ab-0725-4596-9893-497a0a2f14d2","mlflow.runName":"run1","mlflow.rootRunId":"593c74d9-516c-486e-a2ff-7a59e9b05f5c","synapseml.experimentName":"yolov8FT","synapseml.experiment.artifactId":"027202b2-4275-419e-a3e9-55c9425cadfa"}},"inputs":{"dataset_inputs":[]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mMLflow: \u001b[0mresults logged to sds://pbipneu6-northeurope.pbidedicated.windows.net/webapi/capacities/95e21aae-6a0b-49fb-94c1-e430b392fb52/workloads/ML/ML/Automatic/workspaceid/207baa19-22b5-4f4e-a3b0-9a7034fb125a/\n\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ▃▆████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁\n\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▃▆████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁\n\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▃▆████▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁\n\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) ▁▁▃▂▃▃▅▄▅▆▅▆▇▇▇▇▆▇▇█▇█▇█▇▇▇▇▇▇▇▇▇████▇██\n\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▁▁▂▂▃▃▄▃▄▅▅▅▆▆▇▆▅▇▇▇▇▇▆▇▇▇▇▇▇▇▆▇▇▇██▇███\n\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▅█▇▄▂▇▃▂▅▂▁▅▃▆▆▄▅▂▃▇▄▄▄▅▄▄▄▃▄▃▃▃▃▃▃▃▃▃▃▃\n\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) ▁▂▂▄▅▃▄▆▄▆▆▄▇▆▆▆▅▆▆▅▇▇▆▆▇▇▆█▆▇▆▆▇████▇██\n\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▇▆▆▆▆▅▅▅▅▅▅▅▄▅▄▄▄▄▄▄▄▃▄▃▃▃▃▃▃▃▃▂▂▂▂▁▁▁▁\n\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▆▆▆▅▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁\n\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▇▇▆▆▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁\n\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss █▅▃▄▂▂▁▃▂▂▂▂▁▄▁▂▁▄▂▃▂▁▂▂▁▁▂▃▂▂▃▂▃▄▄▂▃▃▃▃\n\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss █▇▅▆▄▄▄▄▃▃▂▃▄▂▂▃▂▂▂▂▂▂▂▁▂▁▁▁▂▁▂▂▁▁▁▁▂▂▂▁\n\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss █▆▃▄▂▃▂▃▃▂▃▂▁▃▁▂▂▄▃▃▂▁▃▂▂▂▃▃▃▂▃▃▃▃▄▃▄▃▄▃\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 4e-05\n\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 4e-05\n\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 4e-05\n\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.27816\n\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.1233\n\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.37462\n\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.33783\n\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 8.204\n\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 3012798\n\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 54.254\n\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.26507\n\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.13752\n\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.5192\n\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 2.09737\n\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.98513\n\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.29046\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mrun1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/alexandru-baila/yolov8FT/runs/y5sep23d\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 24 media file(s), 5 artifact file(s) and 0 other file(s)\n\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240301_072042-y5sep23d/logs\u001b[0m\n"]},{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"ultralytics.utils.metrics.DetMetrics object with attributes:\n\nap_class_index: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\nbox: ultralytics.utils.metrics.Metric object\nconfusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7cc85082fee0>\ncurves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\ncurves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[       0.75,        0.75,        0.75, ...,  8.5824e-05,  4.2912e-05,           0],\n       [          1,           1,           1, ...,  0.00019269,  9.6346e-05,           0],\n       [          1,           1,           1, ...,  0.00041994,  0.00020997,           0],\n       ...,\n       [    0.73913,     0.73913,     0.73913, ...,  0.00053142,  0.00026571,           0],\n       [          1,           1,           1, ...,  0.00078113,  0.00039056,           0],\n       [          1,           1,           1, ...,  0.00091265,  0.00045632,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.016466,     0.01647,    0.022808, ...,           0,           0,           0],\n       [   0.040195,    0.040274,    0.059378, ...,           0,           0,           0],\n       [     0.1938,      0.1938,     0.22377, ...,           0,           0,           0],\n       ...,\n       [   0.081292,    0.081327,     0.12255, ...,           0,           0,           0],\n       [   0.074792,    0.074898,     0.11657, ...,           0,           0,           0],\n       [     0.1194,      0.1194,     0.15991, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[  0.0083179,   0.0083201,    0.011574, ...,           1,           1,           1],\n       [   0.020625,    0.020667,    0.030933, ...,           1,           1,           1],\n       [    0.15625,     0.15625,     0.23678, ...,           1,           1,           1],\n       ...,\n       [   0.042715,    0.042735,     0.06625, ...,           1,           1,           1],\n       [   0.039017,    0.039075,    0.062319, ...,           1,           1,           1],\n       [   0.064159,    0.064159,     0.08857, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.80597,     0.80597,     0.77612, ...,           0,           0,           0],\n       [    0.78571,     0.78571,      0.7381, ...,           0,           0,           0],\n       [     0.2551,      0.2551,     0.21212, ...,           0,           0,           0],\n       ...,\n       [    0.83908,     0.83908,     0.81609, ...,           0,           0,           0],\n       [        0.9,         0.9,         0.9, ...,           0,           0,           0],\n       [    0.85926,     0.85926,     0.82222, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\nfitness: 0.1387821737632246\nkeys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\nmaps: array([   0.046775,    0.074662,    0.053755,     0.15466,    0.088782,    0.033901,   0.0086223,     0.14231,      0.3803,     0.24919])\nnames: {0: 'Acne', 1: 'Atopic Dermatitis', 2: 'Chicken Skin', 3: 'Eczema', 4: 'Hansen-s Disease-Leprosy', 5: 'Hansen-s Disease-Leprosy- severe', 6: 'Healthy skin', 7: 'Psoriasis', 8: 'Ringworm', 9: 'Warts'}\nplot: True\nresults_dict: {'metrics/precision(B)': 0.37461526269254464, 'metrics/recall(B)': 0.33782575511194174, 'metrics/mAP50(B)': 0.2781552550678591, 'metrics/mAP50-95(B)': 0.12329627584048744, 'fitness': 0.1387821737632246}\nsave_dir: PosixPath('yolov8FT/run1')\nspeed: {'preprocess': 0.8175588191900038, 'inference': 53.256711565462275, 'loss': 0.00013175763581928454, 'postprocess': 0.41159292809048986}\ntask: 'detect'"},"metadata":{}}],"execution_count":15,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"892fc1d8-77e8-4e31-8969-78d2fe4c3f3a"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"microsoft":{"language":"python"},"widgets":{},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"nteract":{"version":"nteract-front-end@1.0.0"},"trident":{"lakehouse":{"default_lakehouse":"e0195c4f-be95-4365-8f4e-7d171cd159f8","known_lakehouses":[{"id":"e0195c4f-be95-4365-8f4e-7d171cd159f8"}]}},"spark_compute":{"compute_id":"/trident/default"}},"nbformat":4,"nbformat_minor":5}