{"cells":[{"cell_type":"code","source":["# Welcome to your new notebook\n","# Type here in the cell editor to add code!\n","import os\n","print(os.listdir(\"/lakehouse/default/Files/yaml/\"))"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"496f65ab-0725-4596-9893-497a0a2f14d2","statement_id":5,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-01T07:17:36.3019371Z","session_start_time":null,"execution_start_time":"2024-03-01T07:17:36.917344Z","execution_finish_time":"2024-03-01T07:17:37.7938417Z","parent_msg_id":"cd610e83-19a4-4510-8a07-0566237acdc7"},"text/plain":"StatementMeta(, 496f65ab-0725-4596-9893-497a0a2f14d2, 5, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["['data.yaml']\n"]}],"execution_count":3,"metadata":{},"id":"7e23d74a-58f3-4ba3-9f07-8745df948651"},{"cell_type":"code","source":["print(open(\"/lakehouse/default/Files/yaml/data.yaml\"))"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"496f65ab-0725-4596-9893-497a0a2f14d2","statement_id":6,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-01T07:17:36.4321039Z","session_start_time":null,"execution_start_time":"2024-03-01T07:17:38.2976137Z","execution_finish_time":"2024-03-01T07:17:39.1546862Z","parent_msg_id":"b4cbd3e0-19fd-4dec-9c6d-3dbf27ee772c"},"text/plain":"StatementMeta(, 496f65ab-0725-4596-9893-497a0a2f14d2, 6, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["<_io.TextIOWrapper name='/lakehouse/default/Files/yaml/data.yaml' mode='r' encoding='UTF-8'>\n"]}],"execution_count":4,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"aa5688ec-706e-4265-8c97-701d91d9e063"},{"cell_type":"code","source":["%pip install ultralytics"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":-1,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-01T07:17:36.645713Z","session_start_time":null,"execution_start_time":"2024-03-01T07:18:49.7499122Z","execution_finish_time":"2024-03-01T07:18:49.7500415Z","parent_msg_id":"0d90b958-6c53-4c9b-81fa-e16025612b1b"},"text/plain":"StatementMeta(, , -1, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n  Downloading ultralytics-8.1.20-py3-none-any.whl (716 kB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m716.3/716.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from ultralytics) (3.7.2)\nCollecting opencv-python>=4.6.0 (from ultralytics)\n  Downloading opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m62.2/62.2 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: pillow>=7.1.2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from ultralytics) (10.0.1)\nRequirement already satisfied: pyyaml>=5.3.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from ultralytics) (6.0.1)\nRequirement already satisfied: requests>=2.23.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from ultralytics) (2.31.0)\nRequirement already satisfied: scipy>=1.4.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from ultralytics) (1.10.1)\nRequirement already satisfied: torch>=1.8.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from ultralytics) (2.0.1)\nCollecting torchvision>=0.9.0 (from ultralytics)\n  Downloading torchvision-0.17.1-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m169.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm>=4.64.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from ultralytics) (4.66.1)\nRequirement already satisfied: psutil in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from ultralytics) (5.9.5)\nCollecting py-cpuinfo (from ultralytics)\n  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\nCollecting thop>=0.1.1 (from ultralytics)\n  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\nRequirement already satisfied: pandas>=1.1.4 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from ultralytics) (2.0.3)\nRequirement already satisfied: seaborn>=0.11.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from ultralytics) (0.12.2)\nRequirement already satisfied: contourpy>=1.0.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.1)\nRequirement already satisfied: cycler>=0.10 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.43.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\nRequirement already satisfied: numpy>=1.20 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.1)\nRequirement already satisfied: idna<4,>=2.5 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.17)\nRequirement already satisfied: certifi>=2017.4.17 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\nRequirement already satisfied: filelock in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.11.0)\nRequirement already satisfied: typing-extensions in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.5.0)\nRequirement already satisfied: sympy in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.12)\nRequirement already satisfied: networkx in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.2)\nRequirement already satisfied: jinja2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\nCollecting torch>=1.8.0 (from ultralytics)\n  Downloading torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting typing-extensions>=4.8.0 (from torch>=1.8.0->ultralytics)\n  Downloading typing_extensions-4.10.0-py3-none-any.whl (33 kB)\nRequirement already satisfied: fsspec in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2023.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m115.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m178.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m149.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting triton==2.2.0 (from torch>=1.8.0->ultralytics)\n  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m131.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: six>=1.5 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\nInstalling collected packages: py-cpuinfo, typing-extensions, triton, opencv-python, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, thop, ultralytics\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.5.0\n    Not uninstalling typing-extensions at /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages, outside environment /nfs4/pyenv-6649b43b-a25a-46eb-a35b-07768b3889c6\n    Can't uninstall 'typing_extensions'. No files were found to uninstall.\n  Attempting uninstall: torch\n    Found existing installation: torch 2.0.1\n    Not uninstalling torch at /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages, outside environment /nfs4/pyenv-6649b43b-a25a-46eb-a35b-07768b3889c6\n    Can't uninstall 'torch'. No files were found to uninstall.\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nsentence-transformers 2.0.0 requires sentencepiece, which is not installed.\ndash 2.14.0 requires Flask<2.3.0,>=1.0.4, but you have flask 3.0.0 which is incompatible.\ndash 2.14.0 requires Werkzeug<2.3.0, but you have werkzeug 3.0.1 which is incompatible.\ntensorflow 2.12.1 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 opencv-python-4.9.0.80 py-cpuinfo-9.0.0 thop-0.1.1.post2209072238 torch-2.2.1 torchvision-0.17.1 triton-2.2.0 typing-extensions-4.10.0 ultralytics-8.1.20\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\nWarning: PySpark kernel has been restarted to use updated packages.\n\n"]}],"execution_count":5,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"8d760ddc-ec53-4ae5-ad89-e26302cea014"},{"cell_type":"code","source":["%pip install opencv-python-headless imutils"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":-1,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-01T07:17:36.9829831Z","session_start_time":null,"execution_start_time":"2024-03-01T07:19:08.5260686Z","execution_finish_time":"2024-03-01T07:19:08.526219Z","parent_msg_id":"51c5bf01-2d5a-4d0a-9475-ee7333b218bd"},"text/plain":"StatementMeta(, , -1, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting opencv-python-headless\n  Downloading opencv_python_headless-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting imutils\n  Downloading imutils-0.5.4.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\n\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from opencv-python-headless) (1.24.3)\nBuilding wheels for collected packages: imutils\n  Building wheel for imutils (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\n\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25837 sha256=71c0bb40367a2dee6ead49a3808e82a863917c180494c880c93e7ea787ab26f0\n  Stored in directory: /home/trusted-service-user/.cache/pip/wheels/85/cf/3a/e265e975a1e7c7e54eb3692d6aa4e2e7d6a3945d29da46f2d7\nSuccessfully built imutils\nInstalling collected packages: imutils, opencv-python-headless\nSuccessfully installed imutils-0.5.4 opencv-python-headless-4.9.0.80\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\nWarning: PySpark kernel has been restarted to use updated packages.\n\n"]}],"execution_count":6,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"11abf2b7-9b60-451e-b7ea-24cf7a8f8d76"},{"cell_type":"code","source":["%pip install wandb"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":null,"statement_id":-1,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-01T07:17:37.139662Z","session_start_time":null,"execution_start_time":"2024-03-01T07:19:28.1531886Z","execution_finish_time":"2024-03-01T07:19:28.1533371Z","parent_msg_id":"3394e10f-4b1a-4540-9e62-d10bb3e2289b"},"text/plain":"StatementMeta(, , -1, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: wandb in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (0.15.12)\nRequirement already satisfied: Click!=8.0.0,>=7.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from wandb) (8.1.7)\nRequirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from wandb) (3.1.40)\nRequirement already satisfied: requests<3,>=2.0.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from wandb) (2.31.0)\nRequirement already satisfied: psutil>=5.0.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from wandb) (5.9.5)\nRequirement already satisfied: sentry-sdk>=1.0.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from wandb) (1.32.0)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from wandb) (0.4.0)\nRequirement already satisfied: PyYAML in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from wandb) (6.0.1)\nRequirement already satisfied: pathtools in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from wandb) (0.1.2)\nRequirement already satisfied: setproctitle in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from wandb) (1.3.3)\nRequirement already satisfied: setuptools in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from wandb) (68.2.2)\nRequirement already satisfied: appdirs>=1.4.3 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from wandb) (1.4.4)\nRequirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from wandb) (4.21.12)\nRequirement already satisfied: six>=1.4.0 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\nRequirement already satisfied: charset-normalizer<4,>=2 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.1)\nRequirement already satisfied: idna<4,>=2.5 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.17)\nRequirement already satisfied: certifi>=2017.4.17 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\nRequirement already satisfied: smmap<6,>=3.0.1 in /home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\nWarning: PySpark kernel has been restarted to use updated packages.\n\n"]}],"execution_count":7,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"06d63e02-fe79-4d02-8102-8744513facad"},{"cell_type":"code","source":["import wandb\n","wandb.login(key=\"802e494553876d272ae0c83d17845a2832d2cd29\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"496f65ab-0725-4596-9893-497a0a2f14d2","statement_id":25,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-01T07:17:37.3203304Z","session_start_time":null,"execution_start_time":"2024-03-01T07:19:32.7856934Z","execution_finish_time":"2024-03-01T07:19:40.8110673Z","parent_msg_id":"b8c414bd-3788-4ae6-a696-bba4e4ef9fd5"},"text/plain":"StatementMeta(, 496f65ab-0725-4596-9893-497a0a2f14d2, 25, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/trusted-service-user/.netrc\n"]},{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"True"},"metadata":{}}],"execution_count":8,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"c0dfc771-a9cc-4cd4-bc25-8acb249ad313"},{"cell_type":"code","source":["from ultralytics import YOLO\n","model = YOLO(\"yolov8n\")\n","print(model)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"496f65ab-0725-4596-9893-497a0a2f14d2","statement_id":26,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-01T07:17:37.5535994Z","session_start_time":null,"execution_start_time":"2024-03-01T07:19:41.2007Z","execution_finish_time":"2024-03-01T07:19:51.0619162Z","parent_msg_id":"92068f13-1ca1-41f9-bd42-a61d3115f8d5"},"text/plain":"StatementMeta(, 496f65ab-0725-4596-9893-497a0a2f14d2, 26, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'...\nYOLO(\n  (model): DetectionModel(\n    (model): Sequential(\n      (0): Conv(\n        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (1): Conv(\n        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (2): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (3): Conv(\n        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (4): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0-1): 2 x Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (5): Conv(\n        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (6): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0-1): 2 x Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (7): Conv(\n        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (8): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (9): SPPF(\n        (cv1): Conv(\n          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n      )\n      (10): Upsample(scale_factor=2.0, mode='nearest')\n      (11): Concat()\n      (12): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (13): Upsample(scale_factor=2.0, mode='nearest')\n      (14): Concat()\n      (15): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (16): Conv(\n        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (17): Concat()\n      (18): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (19): Conv(\n        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n        (act): SiLU(inplace=True)\n      )\n      (20): Concat()\n      (21): C2f(\n        (cv1): Conv(\n          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (cv2): Conv(\n          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n          (act): SiLU(inplace=True)\n        )\n        (m): ModuleList(\n          (0): Bottleneck(\n            (cv1): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (cv2): Conv(\n              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n          )\n        )\n      )\n      (22): Detect(\n        (cv2): ModuleList(\n          (0): Sequential(\n            (0): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (1): Sequential(\n            (0): Conv(\n              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (2): Sequential(\n            (0): Conv(\n              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (1): Conv(\n              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n          )\n        )\n        (cv3): ModuleList(\n          (0): Sequential(\n            (0): Conv(\n              (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (1): Conv(\n              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (1): Sequential(\n            (0): Conv(\n              (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (1): Conv(\n              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n          )\n          (2): Sequential(\n            (0): Conv(\n              (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (1): Conv(\n              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n              (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n              (act): SiLU(inplace=True)\n            )\n            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n          )\n        )\n        (dfl): DFL(\n          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        )\n      )\n    )\n  )\n)\n"]},{"output_type":"stream","name":"stderr","text":["100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 6.23M/6.23M [00:00<00:00, 91.4MB/s]\n"]}],"execution_count":9,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"cd8f1f37-7a43-4676-8074-8b3d0d576435"},{"cell_type":"code","source":["yaml = \"/lakehouse/default/Files/yaml/data.yaml\""],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"496f65ab-0725-4596-9893-497a0a2f14d2","statement_id":27,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-01T07:17:37.8121767Z","session_start_time":null,"execution_start_time":"2024-03-01T07:19:51.3612103Z","execution_finish_time":"2024-03-01T07:19:51.5848478Z","parent_msg_id":"3646c5da-3a3a-4e8a-b00b-6e93ccfa49c1"},"text/plain":"StatementMeta(, 496f65ab-0725-4596-9893-497a0a2f14d2, 27, Finished, Available)"},"metadata":{}}],"execution_count":10,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"98b74a20-1bee-4ea6-9be0-af2d7d59ed8d"},{"cell_type":"code","source":["import mlflow"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"496f65ab-0725-4596-9893-497a0a2f14d2","statement_id":28,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-01T07:17:38.050594Z","session_start_time":null,"execution_start_time":"2024-03-01T07:19:51.9139152Z","execution_finish_time":"2024-03-01T07:19:52.1229775Z","parent_msg_id":"6a5081b2-f287-4d80-ba32-a6d8c277eb9a"},"text/plain":"StatementMeta(, 496f65ab-0725-4596-9893-497a0a2f14d2, 28, Finished, Available)"},"metadata":{}}],"execution_count":11,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"882ce713-ec56-4845-94f0-867919f965ac"},{"cell_type":"code","source":["try:\n","    mlflow.search_experiments()\n","    \n","except:\n","    print(\"No experiments yet\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"496f65ab-0725-4596-9893-497a0a2f14d2","statement_id":29,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-01T07:17:38.2193592Z","session_start_time":null,"execution_start_time":"2024-03-01T07:19:52.4178554Z","execution_finish_time":"2024-03-01T07:19:54.7836034Z","parent_msg_id":"a4f5fa75-2355-43d3-afb0-ed0bfa139591"},"text/plain":"StatementMeta(, 496f65ab-0725-4596-9893-497a0a2f14d2, 29, Finished, Available)"},"metadata":{}}],"execution_count":12,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"fa38bec3-02b1-4f82-a384-fc7e28cb181c"},{"cell_type":"code","source":["valid_experiment_name = \"Yolov8_Acne_Eczema_Finetuning2\"\n","mlflow.set_experiment(valid_experiment_name)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"496f65ab-0725-4596-9893-497a0a2f14d2","statement_id":31,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-01T07:17:38.7180751Z","session_start_time":null,"execution_start_time":"2024-03-01T07:19:55.7514478Z","execution_finish_time":"2024-03-01T07:19:56.5194007Z","parent_msg_id":"cc31f4a6-ec8c-47f5-b121-d69af868aed9"},"text/plain":"StatementMeta(, 496f65ab-0725-4596-9893-497a0a2f14d2, 31, Finished, Available)"},"metadata":{}},{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"<Experiment: artifact_location='', creation_time=1709216013414, experiment_id='9d3e91f4-3519-46d1-9088-16b30d693b46', last_update_time=None, lifecycle_stage='active', name='Yolov8_Acne_Eczema_Finetuning2', tags={}>"},"metadata":{}}],"execution_count":14,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"8ead9d92-4dbb-4cdd-bbce-05741a4d8780"},{"cell_type":"code","source":["model.train(data = yaml, \n","            epochs = 50, \n","            imgsz = 640, \n","            batch = 8,\n","            save_period = 5,\n","            project=\"yolov8FT\",  # Set your project directory\n","            name=\"run1\",  # Set a name for this particular training run\n","            exist_ok=True)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"496f65ab-0725-4596-9893-497a0a2f14d2","statement_id":32,"state":"submitted","livy_statement_state":"running","queued_time":"2024-03-01T07:17:38.9318924Z","session_start_time":null,"execution_start_time":"2024-03-01T07:19:56.8873392Z","execution_finish_time":null,"parent_msg_id":"d04f5bdc-cae8-4639-93c2-95f45eec26ff"},"text/plain":"StatementMeta(, 496f65ab-0725-4596-9893-497a0a2f14d2, 32, Submitted, Running)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.1.20 泅 Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon Platinum 8370C 2.80GHz)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/lakehouse/default/Files/yaml/data.yaml, epochs=50, time=None, patience=100, batch=8, imgsz=640, save=True, save_period=5, cache=False, device=None, workers=8, project=yolov8FT, name=run1, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=yolov8FT/run1\nDownloading https://ultralytics.com/assets/Arial.ttf to '/home/trusted-service-user/.config/Ultralytics/Arial.ttf'...\nOverriding model.yaml nc=80 with nc=10\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1    753262  ultralytics.nn.modules.head.Detect           [10, [64, 128, 256]]          \nModel summary: 225 layers, 3012798 parameters, 3012782 gradients, 8.2 GFLOPs\n\nTransferred 319/355 items from pretrained weights\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov8FT/run1', view at http://localhost:6006/\nFreezing layer 'model.22.dfl.conv.weight'\nWARNING 笞ｸ Box and segment counts should be equal, but got len(segments) = 135, len(boxes) = 4940. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\nWARNING 笞ｸ Box and segment counts should be equal, but got len(segments) = 62, len(boxes) = 595. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\nPlotting labels to yolov8FT/run1/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n\u001b[34m\u001b[1mMLflow: \u001b[0mlogging run_id(593c74d9-516c-486e-a2ff-7a59e9b05f5c) to sds://pbipneu6-northeurope.pbidedicated.windows.net/webapi/capacities/95e21aae-6a0b-49fb-94c1-e430b392fb52/workloads/ML/ML/Automatic/workspaceid/207baa19-22b5-4f4e-a3b0-9a7034fb125a/\n\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added 笨\nImage sizes 640 train, 640 val\nUsing 0 dataloader workers\nLogging results to \u001b[1myolov8FT/run1\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.468     0.0625     0.0552     0.0199\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595       0.65      0.109     0.0623     0.0221\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595        0.6      0.103      0.107      0.038\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.445      0.174     0.0979     0.0319\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.541      0.146      0.108     0.0425\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.322      0.208      0.127     0.0454\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.601      0.131      0.133     0.0451\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.361      0.187      0.167     0.0695\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.288      0.257      0.155     0.0553\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.342      0.243      0.165     0.0645\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.457      0.197      0.174     0.0615\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.291      0.276      0.206     0.0801\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.258      0.257      0.188      0.072\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.482      0.167      0.207     0.0785\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.251      0.278      0.195     0.0779\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.367      0.305      0.232     0.0956\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595       0.54      0.248      0.232     0.0927\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.557      0.245      0.256      0.108\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.432      0.266      0.245     0.0958\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.385      0.246      0.233     0.0919\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.476      0.224      0.222     0.0864\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.325      0.275      0.252      0.104\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.385      0.278      0.253      0.106\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.578      0.231      0.277      0.108\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.395      0.274      0.228     0.0915\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.426      0.302      0.249      0.105\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.439      0.298      0.264      0.112\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.418      0.277      0.232     0.0924\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.467      0.252      0.265      0.109\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.513      0.273      0.277      0.108\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.421      0.289      0.261      0.104\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.441      0.284      0.251      0.109\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.441      0.247      0.256      0.108\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.363      0.331      0.257      0.105\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.372      0.324      0.258      0.108\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.405      0.249      0.249      0.105\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.364        0.3      0.254      0.115\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.359      0.274      0.235     0.0939\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.372      0.276       0.26      0.106\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595       0.44       0.29      0.256      0.116\nClosing dataloader mosaic\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.393      0.306      0.259      0.112\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.354      0.334      0.267       0.11\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.381      0.342      0.275      0.119\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.379      0.343      0.277       0.12\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.363      0.312      0.274      0.117\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.383       0.34      0.266      0.115\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.363      0.311      0.262      0.117\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.386      0.344      0.269      0.119\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.384      0.347      0.281       0.12\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n                   all        266        595      0.374      0.337      0.278      0.123\n\n50 epochs completed in 6.419 hours.\nOptimizer stripped from yolov8FT/run1/weights/last.pt, 6.3MB\nOptimizer stripped from yolov8FT/run1/weights/best.pt, 6.3MB\n\nValidating yolov8FT/run1/weights/best.pt...\nUltralytics YOLOv8.1.20 泅 Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon Platinum 8370C 2.80GHz)\nModel summary (fused): 168 layers, 3007598 parameters, 0 gradients, 8.1 GFLOPs\n                   all        266        595      0.375      0.338      0.278      0.123\n                  Acne        266         67      0.244      0.269      0.161     0.0468\n     Atopic Dermatitis        266         42      0.269      0.333      0.261     0.0747\n          Chicken Skin        266         98          1          0      0.142     0.0538\n                Eczema        266         51      0.353      0.471      0.347      0.155\nHansen-s Disease-Leprosy        266         36      0.172      0.194      0.162     0.0888\nHansen-s Disease-Leprosy- severe        266         21      0.298      0.143     0.0918     0.0339\n          Healthy skin        266         28     0.0918     0.0714     0.0256    0.00862\n             Psoriasis        266         87      0.368      0.448      0.328      0.142\n              Ringworm        266         30      0.486        0.8      0.749       0.38\n                 Warts        266        135      0.464      0.649      0.515      0.249\nSpeed: 0.8ms preprocess, 53.3ms inference, 0.0ms loss, 0.4ms postprocess per image\nResults saved to \u001b[1myolov8FT/run1\u001b[0m\n"]},{"output_type":"stream","name":"stderr","text":["100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 755k/755k [00:00<00:00, 17.3MB/s]\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malexandru-baila\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.3 is available!  To upgrade, please run:\n\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.12\n\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/mnt/var/hadoop/tmp/nm-secondary-local-dir/usercache/trusted-service-user/appcache/application_1709276806049_0001/container_1709276806049_0001_01_000001/wandb/run-20240301_072042-y5sep23d\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrun1\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 箝撰ｸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/alexandru-baila/yolov8FT\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: 泅 View run at \u001b[34m\u001b[4mhttps://wandb.ai/alexandru-baila/yolov8FT/runs/y5sep23d\u001b[0m\n\u001b[34m\u001b[1mtrain: \u001b[0mScanning /lakehouse/default/Files/train/labels.cache... 2103 images, 9 backgrounds, 0 corrupt: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 2103/2103 [00:00<?, ?it/s]\n\u001b[34m\u001b[1mval: \u001b[0mScanning /lakehouse/default/Files/valid/labels.cache... 266 images, 2 backgrounds, 0 corrupt: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 266/266 [00:00<?, ?it/s]\n2024/03/01 07:21:31 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n2024/03/01 07:21:31 INFO mlflow.tracking.fluent: Autologging successfully enabled for statsmodels.\n       1/50         0G      1.905       3.87      1.983         49        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:42<00:00,  1.76s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:26<00:00,  1.58s/it]\n       2/50         0G      1.773      3.257       1.89         19        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:37<00:00,  1.74s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:23<00:00,  1.38s/it]\n       3/50         0G      1.757      3.091      1.899         21        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:29<00:00,  1.71s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:21<00:00,  1.25s/it]\n       4/50         0G      1.759       2.96      1.872         16        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:15<00:00,  1.66s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:21<00:00,  1.26s/it]\n       5/50         0G      1.729      2.844      1.843         34        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:13<00:00,  1.65s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:22<00:00,  1.33s/it]\n       6/50         0G      1.715      2.766      1.827         29        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:18<00:00,  1.67s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:20<00:00,  1.22s/it]\n       7/50         0G      1.697      2.684      1.794         24        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:14<00:00,  1.65s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:22<00:00,  1.32s/it]\n       8/50         0G       1.66      2.583      1.798         29        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:14<00:00,  1.65s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:21<00:00,  1.26s/it]\n       9/50         0G      1.672      2.521      1.792         18        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:15<00:00,  1.66s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:23<00:00,  1.37s/it]\n      10/50         0G      1.663      2.462      1.764         36        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:00<00:00,  1.60s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:21<00:00,  1.27s/it]\n      11/50         0G      1.642      2.414      1.774         11        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:16<00:00,  1.66s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:21<00:00,  1.29s/it]\n      12/50         0G      1.638      2.347      1.744         23        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:35<00:00,  1.73s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:23<00:00,  1.37s/it]\n      13/50         0G      1.611      2.293      1.722         21        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:21<00:00,  1.68s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:23<00:00,  1.36s/it]\n      14/50         0G      1.609      2.287      1.739         27        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:19<00:00,  1.67s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:23<00:00,  1.37s/it]\n      15/50         0G      1.602      2.254      1.742         19        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:25<00:00,  1.70s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:22<00:00,  1.31s/it]\n      16/50         0G      1.617      2.215      1.731         22        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:24<00:00,  1.69s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:22<00:00,  1.34s/it]\n      17/50         0G      1.569      2.187      1.711         17        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:08<00:00,  1.63s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:22<00:00,  1.35s/it]\n      18/50         0G      1.598      2.172      1.714         44        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:21<00:00,  1.68s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:21<00:00,  1.29s/it]\n      19/50         0G      1.568      2.095      1.687         25        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:24<00:00,  1.69s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:21<00:00,  1.24s/it]\n      20/50         0G      1.566      2.071      1.688         29        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:07<00:00,  1.63s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:22<00:00,  1.30s/it]\n      21/50         0G       1.56      2.041      1.687         29        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:14<00:00,  1.65s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:21<00:00,  1.29s/it]\n      22/50         0G      1.542      2.003      1.673         17        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:07<00:00,  1.63s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:22<00:00,  1.34s/it]\n      23/50         0G      1.549       1.96       1.66         22        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:05<00:00,  1.62s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:22<00:00,  1.31s/it]\n      24/50         0G       1.53      1.916      1.646         33        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:17<00:00,  1.67s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:21<00:00,  1.29s/it]\n      25/50         0G      1.519        1.9      1.651         31        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:13<00:00,  1.65s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:21<00:00,  1.28s/it]\n      26/50         0G      1.527      1.879      1.648         26        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:14<00:00,  1.65s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:22<00:00,  1.31s/it]\n      27/50         0G        1.5      1.836      1.632         24        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:20<00:00,  1.67s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:20<00:00,  1.18s/it]\n      28/50         0G      1.486      1.816      1.625         34        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:08<00:00,  1.63s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:22<00:00,  1.31s/it]\n      29/50         0G      1.499      1.773       1.62         39        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:26<00:00,  1.70s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:19<00:00,  1.14s/it]\n      30/50         0G      1.483      1.751      1.617         17        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:09<00:00,  1.63s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:21<00:00,  1.24s/it]\n      31/50         0G      1.472      1.716      1.606         19        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:17<00:00,  1.66s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:21<00:00,  1.24s/it]\n      32/50         0G      1.469      1.713      1.609         16        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:04<00:00,  1.62s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:20<00:00,  1.21s/it]\n      33/50         0G      1.458      1.672      1.586         21        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:16<00:00,  1.66s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:21<00:00,  1.25s/it]\n      34/50         0G      1.449      1.636      1.591         21        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:09<00:00,  1.63s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:21<00:00,  1.25s/it]\n      35/50         0G      1.445      1.621       1.58         18        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:13<00:00,  1.65s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:22<00:00,  1.31s/it]\n      36/50         0G      1.436      1.646      1.589         27        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:08<00:00,  1.63s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:20<00:00,  1.22s/it]\n      37/50         0G      1.414      1.555      1.563         21        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:13<00:00,  1.65s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:22<00:00,  1.31s/it]\n      38/50         0G      1.414      1.552      1.561         17        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:00<00:00,  1.60s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:19<00:00,  1.18s/it]\n      39/50         0G      1.411      1.549      1.562         21        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:17<00:00,  1.66s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:21<00:00,  1.27s/it]\n      40/50         0G      1.387      1.491      1.538         18        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:14<00:00,  1.65s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:22<00:00,  1.34s/it]\n      41/50         0G      1.386      1.421      1.607         12        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:04<00:00,  1.61s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:21<00:00,  1.28s/it]\n      42/50         0G      1.362      1.362      1.604         15        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:04<00:00,  1.61s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:20<00:00,  1.23s/it]\n      43/50         0G      1.339       1.28      1.568         20        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:05<00:00,  1.62s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:20<00:00,  1.18s/it]\n      44/50         0G      1.326      1.294       1.57         16        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:11<00:00,  1.64s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:23<00:00,  1.38s/it]\n      45/50         0G      1.309      1.229      1.551         21        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:07<00:00,  1.63s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:21<00:00,  1.29s/it]\n      46/50         0G      1.299      1.203      1.536         13        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:13<00:00,  1.65s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:22<00:00,  1.31s/it]\n      47/50         0G      1.291      1.194      1.533         15        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:09<00:00,  1.63s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:21<00:00,  1.26s/it]\n      48/50         0G      1.283      1.177      1.522         22        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:15<00:00,  1.65s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:22<00:00,  1.31s/it]\n      49/50         0G      1.275      1.146      1.514         18        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:18<00:00,  1.67s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:20<00:00,  1.21s/it]\n      50/50         0G      1.265      1.138      1.519         14        640: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 263/263 [07:16<00:00,  1.66s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:21<00:00,  1.28s/it]\n                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 17/17 [00:15<00:00,  1.06it/s]\n"]},{"output_type":"display_data","data":{"application/vnd.mlflow.run-widget+json":{"info":{"artifact_uri":"sds://onelakenortheurope.pbidedicated.windows.net/207baa19-22b5-4f4e-a3b0-9a7034fb125a/027202b2-4275-419e-a3e9-55c9425cadfa/593c74d9-516c-486e-a2ff-7a59e9b05f5c/artifacts","end_time":1709300832,"experiment_id":"004d3fae-535b-498d-b0a7-4e0933d2da72","lifecycle_stage":"active","run_id":"593c74d9-516c-486e-a2ff-7a59e9b05f5c","run_name":"","run_uuid":"593c74d9-516c-486e-a2ff-7a59e9b05f5c","start_time":1709277691,"status":"FINISHED","user_id":"47b4be73-4385-4eda-a752-da9a9fee5a71"},"data":{"metrics":{"lr/pg0":0.00003541440000000003,"lr/pg2":0.00003541440000000003,"train/dfl_loss":1.5192,"train/box_loss":1.26507,"train/cls_loss":1.13752,"lr/pg1":0.00003541440000000003,"metrics/recallB":0.33782575511194174,"metrics/precisionB":0.37461526269254464,"val/cls_loss":2.98513,"val/box_loss":2.09737,"metrics/mAP50-95B":0.12329627584048744,"val/dfl_loss":2.29046,"metrics/mAP50B":0.2781552550678591},"params":{"task":"detect","mode":"train","model":"yolov8n.pt","data":"/lakehouse/default/Files/yaml/data.yaml","epochs":"50","time":"None","patience":"100","batch":"8","imgsz":"640","save":"True","save_period":"5","cache":"False","device":"None","workers":"0","project":"yolov8FT","name":"run1","exist_ok":"True","pretrained":"True","optimizer":"auto","verbose":"True","seed":"0","deterministic":"True","single_cls":"False","rect":"False","cos_lr":"False","close_mosaic":"10","resume":"False","amp":"True","fraction":"1.0","profile":"False","freeze":"None","multi_scale":"False","overlap_mask":"True","mask_ratio":"4","dropout":"0.0","val":"True","split":"val","save_json":"False","save_hybrid":"False","conf":"None","iou":"0.7","max_det":"300","half":"False","dnn":"False","plots":"True","source":"None","vid_stride":"1","stream_buffer":"False","visualize":"False","augment":"False","agnostic_nms":"False","classes":"None","retina_masks":"False","embed":"None","show":"False","save_frames":"False","save_txt":"False","save_conf":"False","save_crop":"False","show_labels":"True","show_conf":"True","show_boxes":"True","line_width":"None","format":"torchscript","keras":"False","optimize":"False","int8":"False","dynamic":"False","simplify":"False","opset":"None","workspace":"4","nms":"False","lr0":"0.01","lrf":"0.01","momentum":"0.937","weight_decay":"0.0005","warmup_epochs":"3.0","warmup_momentum":"0.8","warmup_bias_lr":"0.0","box":"7.5","cls":"0.5","dfl":"1.5","pose":"12.0","kobj":"1.0","label_smoothing":"0.0","nbs":"64","hsv_h":"0.015","hsv_s":"0.7","hsv_v":"0.4","degrees":"0.0","translate":"0.1","scale":"0.5","shear":"0.0","perspective":"0.0","flipud":"0.0","fliplr":"0.5","mosaic":"1.0","mixup":"0.0","copy_paste":"0.0","auto_augment":"randaugment","erasing":"0.4","crop_fraction":"1.0","cfg":"None","tracker":"botsort.yaml","save_dir":"yolov8FT/run1"},"tags":{"mlflow.user":"9b1bccca-b0b3-4fcf-9df5-fdeabefe9450","synapseml.notebook.artifactId":"281691d8-4c51-46c8-a259-c948faca46f2","synapseml.user.name":"Alexandru Baila","synapseml.user.id":"547b9905-28dd-451c-adad-86d787d2109b","synapseml.livy.id":"496f65ab-0725-4596-9893-497a0a2f14d2","mlflow.runName":"run1","mlflow.rootRunId":"593c74d9-516c-486e-a2ff-7a59e9b05f5c","synapseml.experimentName":"yolov8FT","synapseml.experiment.artifactId":"027202b2-4275-419e-a3e9-55c9425cadfa"}},"inputs":{"dataset_inputs":[]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mMLflow: \u001b[0mresults logged to sds://pbipneu6-northeurope.pbidedicated.windows.net/webapi/capacities/95e21aae-6a0b-49fb-94c1-e430b392fb52/workloads/ML/ML/Automatic/workspaceid/207baa19-22b5-4f4e-a3b0-9a7034fb125a/\n\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 笆笆笆遺毎笆遺毎笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆や魔笆や魔笆や磨笆≫磨\n\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 笆笆笆遺毎笆遺毎笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆や魔笆や魔笆や磨笆≫磨\n\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 笆笆笆遺毎笆遺毎笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆や魔笆や魔笆や磨笆≫磨\n\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 笆≫磨笆笆や麻笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆遺枚笆遺枚笆遺枚笆笆笆笆笆笆笆笆笆遺毎笆遺毎笆笆遺毎\n\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 笆≫磨笆や魔笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆遺毎笆笆遺毎笆\n\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 笆笆遺枚笆笆や枚笆笆や妹笆や磨笆笆笆笆笆笆笆や麻笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆ソn\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 笆≫魔笆や埋笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆遺昧笆笆笆笆笆遺毎笆遺毎笆笆遺毎\n\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 笆―n\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 笆―n\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 笆―n\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 笆遺枚笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆や魔笆や魔笆≫磨笆≫磨\n\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 笆遺昧笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆や魔笆や魔笆や魔笆や魔笆や魔笆≫磨笆≫磨笆≫磨\n\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 笆遺枚笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆笆や魔笆や魔笆や魔笆や魔笆や魔笆や魔笆≫磨笆≫磨\n\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 笆遺妹笆笆笆や魔笆≫麻笆や魔笆や魔笆≫埋笆≫魔笆≫埋笆や麻笆や磨笆や魔笆≫磨笆や麻笆や魔笆笆や麻笆笆笆や麻笆笆笆ソn\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 笆遺枚笆笆笆笆笆笆笆笆笆や麻笆笆や魔笆笆や魔笆や魔笆や魔笆や磨笆や磨笆≫磨笆や磨笆や魔笆≫磨笆≫磨笆や魔笆や磨\n\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 笆遺昧笆笆笆や麻笆や麻笆笆や麻笆や磨笆笆≫魔笆や埋笆笆笆や磨笆笆や魔笆や麻笆笆笆や麻笆笆笆笆笆笆笆笆笆ソn\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 4e-05\n\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 4e-05\n\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 4e-05\n\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.27816\n\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.1233\n\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.37462\n\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.33783\n\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 8.204\n\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 3012798\n\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 54.254\n\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 1.26507\n\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.13752\n\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.5192\n\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 2.09737\n\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 2.98513\n\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 2.29046\n\u001b[34m\u001b[1mwandb\u001b[0m: \n\u001b[34m\u001b[1mwandb\u001b[0m: 泅 View run \u001b[33mrun1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/alexandru-baila/yolov8FT/runs/y5sep23d\u001b[0m\n\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 24 media file(s), 5 artifact file(s) and 0 other file(s)\n\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20240301_072042-y5sep23d/logs\u001b[0m\n"]},{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"ultralytics.utils.metrics.DetMetrics object with attributes:\n\nap_class_index: array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\nbox: ultralytics.utils.metrics.Metric object\nconfusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x7cc85082fee0>\ncurves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\ncurves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[       0.75,        0.75,        0.75, ...,  8.5824e-05,  4.2912e-05,           0],\n       [          1,           1,           1, ...,  0.00019269,  9.6346e-05,           0],\n       [          1,           1,           1, ...,  0.00041994,  0.00020997,           0],\n       ...,\n       [    0.73913,     0.73913,     0.73913, ...,  0.00053142,  0.00026571,           0],\n       [          1,           1,           1, ...,  0.00078113,  0.00039056,           0],\n       [          1,           1,           1, ...,  0.00091265,  0.00045632,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.016466,     0.01647,    0.022808, ...,           0,           0,           0],\n       [   0.040195,    0.040274,    0.059378, ...,           0,           0,           0],\n       [     0.1938,      0.1938,     0.22377, ...,           0,           0,           0],\n       ...,\n       [   0.081292,    0.081327,     0.12255, ...,           0,           0,           0],\n       [   0.074792,    0.074898,     0.11657, ...,           0,           0,           0],\n       [     0.1194,      0.1194,     0.15991, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[  0.0083179,   0.0083201,    0.011574, ...,           1,           1,           1],\n       [   0.020625,    0.020667,    0.030933, ...,           1,           1,           1],\n       [    0.15625,     0.15625,     0.23678, ...,           1,           1,           1],\n       ...,\n       [   0.042715,    0.042735,     0.06625, ...,           1,           1,           1],\n       [   0.039017,    0.039075,    0.062319, ...,           1,           1,           1],\n       [   0.064159,    0.064159,     0.08857, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.80597,     0.80597,     0.77612, ...,           0,           0,           0],\n       [    0.78571,     0.78571,      0.7381, ...,           0,           0,           0],\n       [     0.2551,      0.2551,     0.21212, ...,           0,           0,           0],\n       ...,\n       [    0.83908,     0.83908,     0.81609, ...,           0,           0,           0],\n       [        0.9,         0.9,         0.9, ...,           0,           0,           0],\n       [    0.85926,     0.85926,     0.82222, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\nfitness: 0.1387821737632246\nkeys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\nmaps: array([   0.046775,    0.074662,    0.053755,     0.15466,    0.088782,    0.033901,   0.0086223,     0.14231,      0.3803,     0.24919])\nnames: {0: 'Acne', 1: 'Atopic Dermatitis', 2: 'Chicken Skin', 3: 'Eczema', 4: 'Hansen-s Disease-Leprosy', 5: 'Hansen-s Disease-Leprosy- severe', 6: 'Healthy skin', 7: 'Psoriasis', 8: 'Ringworm', 9: 'Warts'}\nplot: True\nresults_dict: {'metrics/precision(B)': 0.37461526269254464, 'metrics/recall(B)': 0.33782575511194174, 'metrics/mAP50(B)': 0.2781552550678591, 'metrics/mAP50-95(B)': 0.12329627584048744, 'fitness': 0.1387821737632246}\nsave_dir: PosixPath('yolov8FT/run1')\nspeed: {'preprocess': 0.8175588191900038, 'inference': 53.256711565462275, 'loss': 0.00013175763581928454, 'postprocess': 0.41159292809048986}\ntask: 'detect'"},"metadata":{}}],"execution_count":15,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"892fc1d8-77e8-4e31-8969-78d2fe4c3f3a"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"microsoft":{"language":"python"},"widgets":{},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"nteract":{"version":"nteract-front-end@1.0.0"},"trident":{"lakehouse":{"default_lakehouse":"e0195c4f-be95-4365-8f4e-7d171cd159f8","known_lakehouses":[{"id":"e0195c4f-be95-4365-8f4e-7d171cd159f8"}]}},"spark_compute":{"compute_id":"/trident/default"}},"nbformat":4,"nbformat_minor":5}